{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHM_XQC5MA4Z",
        "outputId": "18c7ac74-ca6b-43d2-c7aa-c7cb4220e372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-mxzb7cva\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-mxzb7cva\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=d531b87ed4ab5fb74c14073c46081eecb3b3b610bd3f98971c0671fb3c00a42a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j06d6lkl/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <malloc.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "\n",
        "// ядро\n",
        "__global__ void kernel(double* input, double* output, int n) {\n",
        "    // выделение общей памяти в блоке\n",
        "    extern __shared__ double sdata[];\n",
        "    // получение текущего потока в блоке и размерность блока\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int bdim = blockDim.x;\n",
        "\n",
        "    double sum=0;\n",
        "    // каждый поток складывает значения векторов, начиная со значения, чей индекс равен номеру потока\n",
        "    // и с шагом равным общему числу потоков\n",
        "    for(int i = blockIdx.x * blockDim.x + threadIdx.x; i < n; i += blockDim.x * gridDim.x){\n",
        "        sum += input[i];\n",
        "    }\n",
        "    // сохраняется полученное значение как локальная сумма потока в блоке\n",
        "    sdata[tid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    int step = blockDim.x >> 1;\n",
        "\n",
        "    while(tid + step < bdim && step > 0  ){\n",
        "        sdata[tid] += sdata[tid+step];\n",
        "        bdim = step;\n",
        "        step = step >> 1;\n",
        "        __syncthreads();\n",
        "    }\n",
        "    // сохранение полученного значения в блоке\n",
        "    output[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "\n",
        "// метод подсчета размерностей грида и блока\n",
        "void count_dims(int& blocksPerGrid, int& threadsPerBlock, int n){\n",
        "    int pow = floor(log2((float)n/2));\n",
        "    // оптимальное число потоков для операций над вектором n/2\n",
        "    int numberOfThreads = 1<<pow;\n",
        "    // в зависимости от числа потоков установка числа потоков в блоке\n",
        "    threadsPerBlock = numberOfThreads < 1024 ? numberOfThreads : 1024;\n",
        "    // в зависимости от числа потоков и числа потоков в блоке установка числа блоков в гриде\n",
        "    blocksPerGrid = numberOfThreads < 1024 ? 1 : numberOfThreads / threadsPerBlock;\n",
        "}\n",
        "\n",
        "// функция суммы элементов вектора на GPU\n",
        "double execute_gpu(double* inArray, double* outArray, int n){\n",
        "    // подсчет числа блоков в гриде и числа потоков в блоке\n",
        "    int blocksPerGrid;\n",
        "    int threadsPerBlock;\n",
        "    count_dims(blocksPerGrid, threadsPerBlock, n);\n",
        "\n",
        "\n",
        "     // Выделение памяти на устройстве для копирования самого вектора\n",
        "    double* indev = NULL;\n",
        "    cudaError_t cuerr = cudaMalloc((void**)&indev, n * sizeof(double));\n",
        "    if (cuerr != cudaSuccess) {\n",
        "        fprintf(stderr, \"Cannot allocate device array for indev: %s\\n\",\n",
        "            cudaGetErrorString(cuerr));\n",
        "        return 0;\n",
        "    }\n",
        "    // Выделение памяти на устройстве для промежуточных сумм блоков\n",
        "    double* outdev = NULL;\n",
        "    cuerr = cudaMalloc((void**)&outdev, blocksPerGrid*threadsPerBlock * sizeof(double));\n",
        "    if (cuerr != cudaSuccess) {\n",
        "        fprintf(stderr, \"Cannot allocate device array for outdev: %s\\n\",\n",
        "            cudaGetErrorString(cuerr));\n",
        "        return 0;\n",
        "    }\n",
        "\n",
        "    // Создание обработчиков событий\n",
        "    cudaEvent_t start, stop;\n",
        "    float gpuTime = 0.0f;\n",
        "    cuerr = cudaEventCreate(&start);\n",
        "    if (cuerr != cudaSuccess) {\n",
        "        fprintf(stderr, \"Cannot create CUDA start event: %s\\n\",\n",
        "            cudaGetErrorString(cuerr));\n",
        "        return 0;\n",
        "    }\n",
        "    cuerr = cudaEventCreate(&stop);\n",
        "    if (cuerr != cudaSuccess) {\n",
        "        fprintf(stderr, \"Cannot create CUDA end event: %s\\n\",\n",
        "            cudaGetErrorString(cuerr));\n",
        "        return 0;\n",
        "    }\n",
        "\n",
        "    // Копирование данных вектора с хоста на девайс\n",
        "    cuerr = cudaMemcpy(indev, inArray, n * sizeof(double), cudaMemcpyHostToDevice);\n",
        "    if (cuerr != cudaSuccess) {\n",
        "        fprintf(stderr, \"Cannot copy a array from host to device: %s\\n\",\n",
        "            cudaGetErrorString(cuerr));\n",
        "        return 0;\n",
        "    }\n",
        "\n",
        "    // Установка точки старта\n",
        "    cuerr = cudaEventRecord(start, 0);\n",
        "    if (cuerr != cudaSuccess) {\n",
        "        fprintf(stderr, \"Cannot record CUDA event: %s\\n\",\n",
        "            cudaGetErrorString(cuerr));\n",
        "        return 0;\n",
        "    }\n",
        "\n",
        "    //Запуск ядра\n",
        "    while(n>1){\n",
        "        kernel <<< blocksPerGrid, threadsPerBlock, threadsPerBlock*sizeof(double) >>> (indev, outdev,n);\n",
        "        cuerr = cudaGetLastError();\n",
        "        if (cuerr != cudaSuccess){\n",
        "            fprintf(stderr, \"Cannot launch CUDA kernel: %s\\n\",\n",
        "                cudaGetErrorString(cuerr));\n",
        "            return 0;\n",
        "        }\n",
        "        n = blocksPerGrid;\n",
        "        printf(\"blgr %d\", n);\n",
        "        count_dims(blocksPerGrid, threadsPerBlock, n);\n",
        "        cudaFree(indev);\n",
        "        indev=outdev;\n",
        "        outdev=NULL;\n",
        "        cudaError_t cuerr = cudaMalloc((void**)&outdev, sizeof(double)*n);\n",
        "        if(cuerr!=cudaSuccess){\n",
        "            fprintf(stderr, \"Cannot allocate device array for outdev %s\\n\", cudaGetErrorString(cuerr));\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Синхронизация устройств\n",
        "    cuerr = cudaDeviceSynchronize();\n",
        "    if (cuerr != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Cannot synchronize CUDA kernel: %s\\n\",\n",
        "            cudaGetErrorString(cuerr));\n",
        "        return 0;\n",
        "    }\n",
        "    // Установка точки окончания\n",
        "    cuerr = cudaEventRecord(stop, 0);\n",
        "    if (cuerr != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Cannot copy c array from device to host: %s\\n\",\n",
        "            cudaGetErrorString(cuerr));\n",
        "        return 0;\n",
        "    }\n",
        "\n",
        "    // Копирование результата с девайса на хост\n",
        "    cuerr = cudaMemcpy(outArray, indev, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "    if (cuerr != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Cannot copy c array from device to host: %s\\n\",\n",
        "            cudaGetErrorString(cuerr));\n",
        "        return 0;\n",
        "    }\n",
        "    // подсчет времени\n",
        "    cuerr = cudaEventElapsedTime(&gpuTime, start, stop);\n",
        "    double time = gpuTime/ 1000;\n",
        "\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    cudaFree(indev);\n",
        "    cudaFree(outdev);\n",
        "    return time;\n",
        "}\n",
        "\n",
        "\n",
        "// функция суммы элементов вектора на cpu\n",
        "double execute_cpu(double* inp, double* outp, int n){\n",
        "  double time = clock();\n",
        "  double sum=0;\n",
        "  for (int i=0; i<n; ++i){\n",
        "      sum+=inp[i];\n",
        "  }\n",
        "  outp[0]=sum;\n",
        "  //printf(\"CPU %f\\n\", outp[0]);\n",
        "  double endTime= clock()-time;\n",
        "  return endTime/=CLOCKS_PER_SEC;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "// основная функция\n",
        "int main(int argc, char* argv[])\n",
        "{\n",
        "    // размерность матриц\n",
        "    int n = 8192;\n",
        "\n",
        "    // Выделение памяти на хосте\n",
        "    double* input = (double*)malloc(sizeof(double)*n);\n",
        "    double* output_cpu=(double*)malloc(sizeof(double));\n",
        "    double* output_gpu=(double*)malloc(sizeof(double));\n",
        "\n",
        "\n",
        "    // заполнение матриц\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        input[i] = 1;\n",
        "    }\n",
        "    double time_cpu=0;\n",
        "    double time_gpu=0;\n",
        "    // цикл для усреднения значений\n",
        "    for(int k=0;k<32;++k){\n",
        "        // вызов суммы элементов вектора на CPU\n",
        "        time_cpu += execute_cpu(input, output_cpu, n);\n",
        "        // вызов суммы элементов вектора на GPU\n",
        "        time_gpu += execute_gpu(input,  output_gpu, n);\n",
        "\n",
        "    }\n",
        "    printf(\"SUM VECTOR'S ELEMENTS ON CPU: %f;\\nTIME_CPU: %f\\n\", output_cpu[0], time_cpu/32);\n",
        "    printf(\"SUM VECTOR'S ELEMENTS ON GPU: %f;\\nTIME_GPU: %f\\n\", output_gpu[0], time_gpu/32);\n",
        "    // подсчет ускорения\n",
        "    printf(\"A: %f\\n\", time_cpu/time_gpu);\n",
        "    // освобождение выделенной памяти\n",
        "    free(input);\n",
        "    free(output_cpu);\n",
        "    free(output_gpu);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHxkny96M3hD",
        "outputId": "f15056fa-8120-4721-cfce-39f9f5bcbbc5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1blgr 4blgr 1SUM VECTOR'S ELEMENTS ON CPU: 8192.000000;\n",
            "TIME_CPU: 0.000029\n",
            "SUM VECTOR'S ELEMENTS ON GPU: 8192.000000;\n",
            "TIME_GPU: 0.000050\n",
            "A: 0.584518\n",
            "\n"
          ]
        }
      ]
    }
  ]
}